{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4629fdc-a6d0-49e9-9875-990b8ba3bd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kenlm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyctcdecode import build_ctcdecoder\n",
    "import soundfile as sf\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbab25f-8f9d-4d53-9ea3-c8b2dcfb80f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ee42df-0256-45a6-9b05-ad6ea636f866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf8ba37-fe5d-43fd-866a-df44b6724a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b58a5-ee5d-4c49-bfe3-f3bb8ee20c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7043a-78e1-43fe-a863-e53133891351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429c14d-c78e-4ebc-ac12-7f79553e2be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e12bdc-e7b4-4d20-be13-f512c7f6e24a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "979efee2-d8bf-4457-b3d9-e4367846dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# greedy decode algorithm\n",
    "def greedy_decode(logits, labels):\n",
    "    \"\"\"Decode argmax of logits and squash in CTC fashion.\"\"\"\n",
    "    label_dict = {n: c for n, c in enumerate(labels)}\n",
    "    prev_c = None\n",
    "    out = []\n",
    "    for n in logits.argmax(axis=1):\n",
    "        c = label_dict.get(n, \"\")  # if not in labels, then assume it's ctc blank char\n",
    "        if c != prev_c:\n",
    "            out.append(c)\n",
    "        prev_c = c\n",
    "    return \"\".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc448c41-c459-4900-8308-90bc6b9666b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "KENLM_MODEL_LOC = 'lm/4gram_big.arpa.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74abd01e-4422-4f67-b958-9476353cc6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the finetuned model and the processor\n",
    "asr_model = Wav2Vec2ForCTC.from_pretrained('./saved_model/')\n",
    "asr_processor = Wav2Vec2Processor.from_pretrained('./processor/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cc15627-9047-4d22-9e79-45c24b9e7335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab:  {'R': 0, 'Y': 1, 'H': 2, 'S': 3, 'C': 4, 'N': 5, 'L': 6, 'M': 7, 'B': 8, 'A': 9, 'I': 10, 'X': 11, 'V': 12, 'G': 13, 'W': 14, 'J': 15, 'E': 16, 'D': 17, 'Q': 18, 'Z': 19, 'T': 20, 'U': 21, 'K': 22, 'P': 23, 'O': 24, 'F': 25, \"'\": 26, '|': 27, '[UNK]': 28, '[PAD]': 29, '<s>': 30, '</s>': 31}\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocab: \", asr_processor.tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01addfac-5737-4960-922e-453fe3544bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R', 'Y', 'H', 'S', 'C', 'N', 'L', 'M', 'B', 'A', 'I', 'X', 'V', 'G', 'W', 'J', 'E', 'D', 'Q', 'Z', 'T', 'U', 'K', 'P', 'O', 'F', \"'\", '|', '[UNK]', '[PAD]', '<s>', '</s>']\n"
     ]
    }
   ],
   "source": [
    "vocab = list(asr_processor.tokenizer.get_vocab().keys())\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e578416-f477-40ac-847c-f1f39551456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert some vocabs\n",
    "vocab[vocab.index('[PAD]')] = '_'\n",
    "vocab[vocab.index('|')] = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc5bafda-754d-4b69-8683-2fd2d68764af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R', 'Y', 'H', 'S', 'C', 'N', 'L', 'M', 'B', 'A', 'I', 'X', 'V', 'G', 'W', 'J', 'E', 'D', 'Q', 'Z', 'T', 'U', 'K', 'P', 'O', 'F', \"'\", ' ', '[UNK]', '_', '<s>', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d65937-df21-4aed-9923-42993582102b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d413605f-c85c-4777-a32e-c13b524fdd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /w2v2_kenlm_pipeline/lm/4gram_big.arpa.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "Unigrams not provided and cannot be automatically determined from LM file (only arpa format). Decoding accuracy might be reduced.\n",
      "****************************************************************************************************\n",
      "Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?\n",
      "No known unigrams provided, decoding results might be a lot worse.\n"
     ]
    }
   ],
   "source": [
    "# build the decoder\n",
    "decoder = build_ctcdecoder(\n",
    "    labels = vocab,\n",
    "    kenlm_model_path = KENLM_MODEL_LOC,\n",
    "    alpha=0.6,  # tuned on a val set\n",
    "    beta=2.0,  # tuned on a val set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fc9376e9-1ed4-4aff-915e-899404b80bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = './datasets/magister_data_flac_16000/test/11039/2614000/11039-2614000-0053.flac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "558f46cf-727b-4964-8807-eabc11f5fdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get logits\n",
    "arr, _ = sf.read(audio_path)\n",
    "input_values = asr_processor(arr, return_tensors=\"pt\", sampling_rate=16000).input_values  # Batch size 1\n",
    "logits = asr_model(input_values).logits.cpu().detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3ada70f9-329a-4360-8aa1-e7969d672166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.44140625e-04, -1.86157227e-03, -3.47900391e-03, -3.32641602e-03,\n",
       "       -3.14331055e-03, -2.22778320e-03, -1.28173828e-03, -9.15527344e-05,\n",
       "        1.09863281e-03,  1.64794922e-03,  2.22778320e-03,  3.66210938e-04,\n",
       "       -1.49536133e-03, -4.66918945e-03, -7.84301758e-03, -9.76562500e-03,\n",
       "       -1.16882324e-02, -1.10168457e-02, -1.03454590e-02, -7.26318359e-03,\n",
       "       -4.15039062e-03, -1.19018555e-03,  1.80053711e-03,  3.20434570e-03,\n",
       "        4.63867188e-03,  6.01196289e-03,  7.41577148e-03,  6.95800781e-03,\n",
       "        6.50024414e-03,  6.43920898e-03,  6.37817383e-03,  8.33129883e-03,\n",
       "        1.02844238e-02,  1.14135742e-02,  1.25732422e-02,  1.25732422e-02,\n",
       "        1.25732422e-02,  9.33837891e-03,  6.10351562e-03,  1.67846680e-03,\n",
       "       -2.71606445e-03, -5.34057617e-03, -7.96508789e-03, -9.27734375e-03,\n",
       "       -1.05895996e-02, -1.06201172e-02, -1.06201172e-02, -9.94873047e-03,\n",
       "       -9.24682617e-03, -9.61303711e-03])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9519805-a80d-414f-b12a-a787ab3083d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e3365-2696-42cc-a882-c220423348a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d708144-84d8-4504-951b-133a0682a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pkl/magister_data_flac_16000_test.pkl', 'rb') as f:\n",
    "    df_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8ac9c15f-1c3a-4899-bfdc-33be442b88d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['file', 'audio', 'text'],\n",
       "    num_rows: 334\n",
       "})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_data = Dataset.from_pandas(df_test)\n",
    "df_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0ae3e2b4-f7db-4673-b3dd-6f8bef6dee0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/magister_data_flac_16000/test/11039/2614000/11039-2614000-0053.flac\n"
     ]
    }
   ],
   "source": [
    "print(df_test_data[0]['audio']['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6d3ff8b1-0c3d-4884-bd91-b05dfd86a1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.000244140625, -0.001861572265625, -0.00347900390625, -0.003326416015625, -0.003143310546875, -0.002227783203125, -0.00128173828125, -9.1552734375e-05, 0.0010986328125, 0.00164794921875, 0.002227783203125, 0.0003662109375, -0.001495361328125, -0.004669189453125, -0.007843017578125, -0.009765625, -0.011688232421875, -0.011016845703125, -0.010345458984375, -0.00726318359375, -0.004150390625, -0.001190185546875, 0.001800537109375, 0.003204345703125, 0.004638671875, 0.006011962890625, 0.007415771484375, 0.0069580078125, 0.006500244140625, 0.006439208984375, 0.006378173828125, 0.008331298828125, 0.010284423828125, 0.01141357421875, 0.0125732421875, 0.0125732421875, 0.0125732421875, 0.00933837890625, 0.006103515625, 0.001678466796875]\n"
     ]
    }
   ],
   "source": [
    "# audio array\n",
    "print(df_test_data[0]['audio']['array'][:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8259cc1d-0a52-43a7-a600-c47b206f1023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.44140625e-04, -1.86157227e-03, -3.47900391e-03, ...,\n",
       "       -2.13623047e-04, -6.10351562e-05,  1.22070312e-04])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# audio array needs to be converted to numpy array again\n",
    "np.array(df_test_data[0]['audio']['array'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9cbde628-cc03-44fe-a481-dfb80ffbb788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOW INCREASE ONE THREE\n"
     ]
    }
   ],
   "source": [
    "# ground truth text\n",
    "print(df_test_data[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc95caf-eec2-4fa6-9ec8-d8e75fd63ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c5bc190c-7940-4098-b506-b70be26da102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.135748  ,  1.7107844 ,  1.3733399 , ..., 14.112412  ,\n",
       "        -1.7596617 , -1.1428883 ],\n",
       "       [ 1.1059318 ,  1.5879831 ,  1.2237644 , ..., 14.059038  ,\n",
       "        -1.8348356 , -1.3138465 ],\n",
       "       [ 0.21142852,  1.9927497 ,  1.7712679 , ..., 13.7063265 ,\n",
       "        -1.67544   , -1.1022942 ],\n",
       "       ...,\n",
       "       [-0.4605291 ,  2.3351345 ,  3.1894143 , ..., 12.909706  ,\n",
       "        -1.1828046 , -1.0336481 ],\n",
       "       [-0.30894375,  2.5699425 ,  2.9037273 , ..., 14.281372  ,\n",
       "        -1.0672334 , -0.8433927 ],\n",
       "       [ 0.21268058,  1.9065666 ,  1.7108347 , ..., 13.669061  ,\n",
       "        -1.7176361 , -1.1836007 ]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "07b8c211-a97c-42e8-898c-e681549c6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = decoder.decode(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "37e1e515-927b-4375-8c27-4842afdf368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get greedy decoding\n",
    "greedy_text = greedy_decode(logits, vocab)\n",
    "greedy_text = (\"\".join(c for c in greedy_text if c not in [\"_\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "16aa6d5c-ad52-4ea2-86ab-9d4d3188c9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Decoding: \n",
      "ALL STATION THIS IS PWO STAND BY FOR SITREP ONE EXTERNAL FOLLOW BYTE GUNERY BROADCAST\n",
      "\n",
      "\n",
      "Language Model Decoding: \n",
      "ALL STATION THIS IS STANDBY FOR SITREPONEEXTERNAL FOLLOBYGUNERY BROADCAST\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Greedy Decoding: \\n\" + greedy_text)\n",
    "print(\"\\n\")\n",
    "print(\"Language Model Decoding: \\n\" + text)\n",
    "print(\"\\n\")\n",
    "# print(\"Ground truth \\n\" + true_text)\n",
    "# print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1aad2f-9a71-4037-90dd-9c12d6565267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca28b78-f591-486d-b21a-59a63220403b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c03bc2-e46f-436b-a5bf-5091c219808b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefade0f-ec5c-49dd-9a50-25f7d36508dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "861986f4-17f0-47a1-9d7f-9f5ff205a373",
   "metadata": {},
   "source": [
    "## The code to decode all the test audio and obtain the WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d20ab404-e1cb-49b2-a402-bd9e396d9f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# greedy decode algorithm\n",
    "def greedy_decode(logits, labels):\n",
    "    \"\"\"Decode argmax of logits and squash in CTC fashion.\"\"\"\n",
    "    label_dict = {n: c for n, c in enumerate(labels)}\n",
    "    prev_c = None\n",
    "    out = []\n",
    "    for n in logits.argmax(axis=1):\n",
    "        c = label_dict.get(n, \"\")  # if not in labels, then assume it's ctc blank char\n",
    "        if c != prev_c:\n",
    "            out.append(c)\n",
    "        prev_c = c\n",
    "    return \"\".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beaef679-5517-45ed-b507-adc6b7cbfaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "KENLM_MODEL_LOC = 'lm/4gram_big.arpa.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8fcc037-e182-43b7-8ed9-711e9185e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the finetuned model and the processor\n",
    "asr_model = Wav2Vec2ForCTC.from_pretrained('./saved_model/')\n",
    "asr_processor = Wav2Vec2Processor.from_pretrained('./processor/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a64ca216-5d33-4dbd-ab1b-7682308f70de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: {'R': 0, 'Y': 1, 'H': 2, 'S': 3, 'C': 4, 'N': 5, 'L': 6, 'M': 7, 'B': 8, 'A': 9, 'I': 10, 'X': 11, 'V': 12, 'G': 13, 'W': 14, 'J': 15, 'E': 16, 'D': 17, 'Q': 18, 'Z': 19, 'T': 20, 'U': 21, 'K': 22, 'P': 23, 'O': 24, 'F': 25, \"'\": 26, '|': 27, '[UNK]': 28, '[PAD]': 29, '<s>': 30, '</s>': 31}\n",
      "\n",
      "Vocab List: ['R', 'Y', 'H', 'S', 'C', 'N', 'L', 'M', 'B', 'A', 'I', 'X', 'V', 'G', 'W', 'J', 'E', 'D', 'Q', 'Z', 'T', 'U', 'K', 'P', 'O', 'F', \"'\", '|', '[UNK]', '[PAD]', '<s>', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(f'Vocab: {asr_processor.tokenizer.get_vocab()}')\n",
    "print()\n",
    "vocab = list(asr_processor.tokenizer.get_vocab().keys())\n",
    "print(f'Vocab List: {vocab}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e98abdf-863d-4b73-8e74-e9fec7012d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R', 'Y', 'H', 'S', 'C', 'N', 'L', 'M', 'B', 'A', 'I', 'X', 'V', 'G', 'W', 'J', 'E', 'D', 'Q', 'Z', 'T', 'U', 'K', 'P', 'O', 'F', \"'\", ' ', '[UNK]', '_', '<s>', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# convert some vocabs\n",
    "vocab[vocab.index('[PAD]')] = '_'\n",
    "vocab[vocab.index('|')] = ' '\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ab9b28a-1edc-426e-91d8-310d36b4010e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unigrams not provided and cannot be automatically determined from LM file (only arpa format). Decoding accuracy might be reduced.\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /w2v2_kenlm_pipeline/lm/4gram_big.arpa.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?\n",
      "No known unigrams provided, decoding results might be a lot worse.\n"
     ]
    }
   ],
   "source": [
    "# build the decoder\n",
    "decoder = build_ctcdecoder(\n",
    "    labels = vocab,\n",
    "    kenlm_model_path = KENLM_MODEL_LOC,\n",
    "    alpha=0.6,  # tuned on a val set\n",
    "    beta=2.0,  # tuned on a val set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ee5b3e1-4c13-41d2-a599-77f330496d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['file', 'audio', 'text'],\n",
       "    num_rows: 334\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the test set data for evaluation\n",
    "with open('./pkl/magister_data_flac_16000_test.pkl', 'rb') as f:\n",
    "    df_test = pickle.load(f)\n",
    "\n",
    "# convert the data into a huggingface Dataset object\n",
    "df_test_data = Dataset.from_pandas(df_test)\n",
    "df_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edcfdfe-8255-42e4-b8ac-6e2b17dd2216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbb1ec78-399b-4ee7-a45d-b80645ed5d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/magister_data_flac_16000/test/11039/2614000/11039-2614000-0053.flac\n"
     ]
    }
   ],
   "source": [
    "print(df_test_data[0]['audio']['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da56e135-77dc-4627-aca2-8f5ee81ce40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.44140625e-04, -1.86157227e-03, -3.47900391e-03, ...,\n",
       "       -2.13623047e-04, -6.10351562e-05,  1.22070312e-04])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# audio array needs to be converted to numpy array again\n",
    "np.array(df_test_data[0]['audio']['array'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3351ac1f-c53b-4cf9-b2e0-754830576018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOW INCREASE ONE THREE\n"
     ]
    }
   ],
   "source": [
    "# ground truth text\n",
    "print(df_test_data[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0df489-6b3d-4843-aa7a-b64759cca644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cd968ca-2dde-456c-a4fe-684b781f5278",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15/2758933285.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0maudio_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'audio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'array'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minput_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masr_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_values\u001b[0m  \u001b[0;31m# Batch size 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masr_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'arr' is not defined"
     ]
    }
   ],
   "source": [
    "# get logits\n",
    "audio_array = np.array(df_test_data[0]['audio']['array'])\n",
    "input_values = asr_processor(arr, return_tensors=\"pt\", sampling_rate=16000).input_values  # Batch size 1\n",
    "logits = asr_model(input_values).logits.cpu().detach().numpy()[0]\n",
    "\n",
    "# beam search decoding \n",
    "text = decoder.decode(logits)\n",
    "\n",
    "# greedy search decoding\n",
    "greedy_text = greedy_decode(logits, vocab)\n",
    "greedy_text = (\"\".join(c for c in greedy_text if c not in [\"_\"]))\n",
    "\n",
    "# ground truth\n",
    "ground_truth_text = df_test_data[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4dd4dae9-1aa0-4f9a-8d53-3265f5964cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam Search: OW INCREASE ONE THREE\n",
      "\n",
      "Greedy Search: OW INCREASE ONE THREE\n",
      "\n",
      "Ground Truth: OOW INCREASE ONE THREE\n"
     ]
    }
   ],
   "source": [
    "print(f'Beam Search: {text}\\n')\n",
    "print(f'Greedy Search: {greedy_text}\\n')\n",
    "print(f'Ground Truth: {ground_truth_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36360838-8038-427d-836f-4301bc3490ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb92363-79a4-4702-b3f6-5dc22dbfc981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b26b749-94f6-4984-a0ac-f134a57ad47e",
   "metadata": {},
   "source": [
    "## Actual code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "223f3b81-8435-48ed-90df-972c9dd458ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# greedy decode algorithm\n",
    "def greedy_decode(logits, labels):\n",
    "    \"\"\"Decode argmax of logits and squash in CTC fashion.\"\"\"\n",
    "    label_dict = {n: c for n, c in enumerate(labels)}\n",
    "    prev_c = None\n",
    "    out = []\n",
    "    for n in logits.argmax(axis=1):\n",
    "        c = label_dict.get(n, \"\")  # if not in labels, then assume it's ctc blank char\n",
    "        if c != prev_c:\n",
    "            out.append(c)\n",
    "        prev_c = c\n",
    "    return \"\".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5530e6fc-ef0f-4d25-b753-6e2dd0673af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "894d6c80-0725-45fa-a35b-b3bf8c9aa6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /w2v2_kenlm_pipeline/magister_lm.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?\n",
      "****************************************************************************************************\n",
      "Unigrams and labels don't seem to agree.\n"
     ]
    }
   ],
   "source": [
    "# load the finetuned model and the processor\n",
    "asr_model = Wav2Vec2ForCTC.from_pretrained('./saved_model/')\n",
    "asr_processor = Wav2Vec2Processor.from_pretrained('./processor/')\n",
    "\n",
    "# load the kenlm language model\n",
    "#KENLM_MODEL_LOC = 'lm/4gram_big.arpa.gz'\n",
    "KENLM_MODEL_LOC = 'magister_lm.arpa'\n",
    "\n",
    "# get the vocab list from the dictionary\n",
    "vocab = list(asr_processor.tokenizer.get_vocab().keys())\n",
    "\n",
    "# convert some vocabs\n",
    "vocab[vocab.index('[PAD]')] = '_'\n",
    "vocab[vocab.index('|')] = ' '\n",
    "\n",
    "# build the decoder\n",
    "decoder = build_ctcdecoder(\n",
    "    labels = vocab,\n",
    "    kenlm_model_path = KENLM_MODEL_LOC,\n",
    "    alpha=0.6,  # tuned on a val set\n",
    "    beta=2.0,  # tuned on a val set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36922a2d-1831-45c3-9a25-7b53fa77815d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d7d00bb-2cf0-4d7d-8714-6cbeeab3783e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['file', 'audio', 'text'],\n",
       "    num_rows: 334\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the test set data for evaluation\n",
    "with open('./pkl/magister_data_flac_16000_test.pkl', 'rb') as f:\n",
    "    df_test = pickle.load(f)\n",
    "\n",
    "# convert the data into a huggingface Dataset object\n",
    "data_test = Dataset.from_pandas(df_test)\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70c2a366-7980-43f0-9603-5b500033142d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "334it [03:13,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "ground_truth_list = []\n",
    "pred_beam_search_list = []\n",
    "pred_greedy_search_list = []\n",
    "# append the text and predictions into lists\n",
    "for idx, entry in tqdm(enumerate(data_test)):\n",
    "    # get logits\n",
    "    audio_array = np.array(data_test[idx]['audio']['array'])\n",
    "    input_values = asr_processor(audio_array, return_tensors=\"pt\", sampling_rate=16000).input_values  # Batch size 1\n",
    "    logits = asr_model(input_values).logits.cpu().detach().numpy()[0]\n",
    "\n",
    "    # beam search decoding \n",
    "    beam_text = decoder.decode(logits)\n",
    "\n",
    "    # greedy search decoding\n",
    "    greedy_text = greedy_decode(logits, vocab)\n",
    "    greedy_text = (\"\".join(c for c in greedy_text if c not in [\"_\"]))\n",
    "\n",
    "    # ground truth\n",
    "    ground_truth_text = data_test[idx]['text']\n",
    "    \n",
    "    # appending the data to the individual lists\n",
    "    ground_truth_list.append(ground_truth_text)\n",
    "    pred_beam_search_list.append(beam_text)\n",
    "    pred_greedy_search_list.append(greedy_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5254de-829f-4170-8bb8-b3a5f7e40c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3873dd4-50c5-448c-bb3a-3d0871fba62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define evaluation metric\n",
    "wer_metric = load_metric(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bfcd6d-efb2-4d56-8e61-e87149c60087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f92a9e5e-030f-473f-ac36-eb6edfc69ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER (greedy search): 0.24384\n",
      "\n",
      "WER (beam search): 0.18310\n"
     ]
    }
   ],
   "source": [
    "# alpha 0.6 beta 2.0 - 5 gram (beam search)\n",
    "print(\"WER (greedy search): {:.5f}\".format(wer_metric.compute(predictions=pred_greedy_search_list, references=ground_truth_list)))\n",
    "print()\n",
    "print(\"WER (beam search): {:.5f}\".format(wer_metric.compute(predictions=pred_beam_search_list, references=ground_truth_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c657ecae-5eea-4814-bdfe-d28599a67ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bff8c78-8e80-42f0-abb5-2068ed860288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER (greedy search): 0.24384\n",
      "\n",
      "WER (beam search): 0.18277\n"
     ]
    }
   ],
   "source": [
    "# alpha 0.6 beta 2.0 - 4 gram (beam search)\n",
    "print(\"WER (greedy search): {:.5f}\".format(wer_metric.compute(predictions=pred_greedy_search_list, references=ground_truth_list)))\n",
    "print()\n",
    "print(\"WER (beam search): {:.5f}\".format(wer_metric.compute(predictions=pred_beam_search_list, references=ground_truth_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce882e26-16f7-47bb-b50c-29ed6aac9117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccf05260-4aac-4052-b754-4680412afda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER (greedy search): 0.24384\n",
      "\n",
      "WER (beam search): 0.18321\n"
     ]
    }
   ],
   "source": [
    "# alpha 0.6 beta 2.0 - 3 gram (beam search)\n",
    "print(\"WER (greedy search): {:.5f}\".format(wer_metric.compute(predictions=pred_greedy_search_list, references=ground_truth_list)))\n",
    "print()\n",
    "print(\"WER (beam search): {:.5f}\".format(wer_metric.compute(predictions=pred_beam_search_list, references=ground_truth_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89409a28-8346-4966-bdbf-a4f5d730ba72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
