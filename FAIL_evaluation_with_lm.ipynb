{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d195c4a-20d6-4ea6-b633-a6815044e65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr  6 14:59:03 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.00    Driver Version: 470.82.00    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   58C    P8    20W /  N/A |    718MiB / 16125MiB |      9%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72dea28a-a23a-4c97-9b7a-6b5216beab1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from decoder import *\n",
    "import utils\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Wav2Vec2CTCTokenizer\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45650ee2-1e3d-4492-ba2e-e47552722e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the finetuned model and the processor\n",
    "model = Wav2Vec2ForCTC.from_pretrained('./saved_model/')\n",
    "processor = Wav2Vec2Processor.from_pretrained('./processor/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bc0d00e-6f2f-44fa-b6e6-d88d059fede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Dict: {'G': 0, 'A': 1, 'E': 2, '-': 3, \"'\": 4, 'Y': 5, 'S': 6, 'K': 7, 'O': 8, 'L': 9, 'Z': 10, 'H': 11, 'Q': 12, 'W': 13, 'T': 14, 'J': 15, 'B': 16, 'D': 17, 'U': 18, 'M': 19, 'F': 21, 'C': 22, 'P': 23, 'I': 24, '#': 25, 'R': 26, 'V': 27, 'X': 28, 'N': 29, '|': 20, '[UNK]': 30, '[PAD]': 31, '<s>': 32, '</s>': 33}\n"
     ]
    }
   ],
   "source": [
    "vocab_dict = processor.tokenizer.get_vocab()\n",
    "print(f'Vocab Dict: {vocab_dict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2baec7f2-c6e9-4725-93b9-bbc997267ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'G'), (1, 'A'), (2, 'E'), (3, '-'), (4, \"'\"), (5, 'Y'), (6, 'S'), (7, 'K'), (8, 'O'), (9, 'L'), (10, 'Z'), (11, 'H'), (12, 'Q'), (13, 'W'), (14, 'T'), (15, 'J'), (16, 'B'), (17, 'D'), (18, 'U'), (19, 'M'), (20, '|'), (21, 'F'), (22, 'C'), (23, 'P'), (24, 'I'), (25, '#'), (26, 'R'), (27, 'V'), (28, 'X'), (29, 'N'), (30, '[UNK]'), (31, '[PAD]'), (32, '<s>'), (33, '</s>')]\n"
     ]
    }
   ],
   "source": [
    "sort_vocab = sorted((value, key) for (key,value) in vocab_dict.items())\n",
    "print(sort_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc3332f8-19b4-4212-8d75-1d5375cd209a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G', 'A', 'E', '-', \"'\", 'Y', 'S', 'K', 'O', 'L', 'Z', 'H', 'Q', 'W', 'T', 'J', 'B', 'D', 'U', 'M', '|', 'F', 'C', 'P', 'I', '#', 'R', 'V', 'X', 'N', '[UNK]', '[PAD]', '<s>', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# Lower case ALL letters\n",
    "vocab = []\n",
    "for _, token in sort_vocab:\n",
    "    vocab.append(token)\n",
    "    \n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "199d9194-e2bf-40ad-8476-87507117bc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.word_delimiter_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac974fd7-4e09-4fe0-aa19-b53fe1ce6126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G', 'A', 'E', '-', \"'\", 'Y', 'S', 'K', 'O', 'L', 'Z', 'H', 'Q', 'W', 'T', 'J', 'B', 'D', 'U', 'M', ' ', 'F', 'C', 'P', 'I', '#', 'R', 'V', 'X', 'N', '[UNK]', '[PAD]', '<s>', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# replace the word delimiter with a white space since the white space is used by the decoders\n",
    "# only can run once\n",
    "vocab[vocab.index(processor.tokenizer.word_delimiter_token)] = ' '\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e17967b-3f19-46bb-81d5-fca3b2347b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4cdb4a9-045d-4f0e-a25a-dec1d20adf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the lm path\n",
    "lm_path = \"lm/4gram_big.arpa.gz\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3658d63-623a-422d-b525-59829c06511f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading lm/4gram_big.arpa.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# alpha, beta, and beam_wdith SHOULD be tuned on the dev-set to get the best settings\n",
    "# Feel free to check other inputs of the BeamCTCDecoder\n",
    "alpha=0\n",
    "beta=0\n",
    "beam_width = 1024\n",
    "\n",
    "beam_decoder = BeamCTCDecoder(vocab, lm_path=lm_path,\n",
    "                                 alpha=alpha, beta=beta,\n",
    "                                 cutoff_top_n=40, cutoff_prob=1.0,\n",
    "                                 beam_width=beam_width, num_processes=16,\n",
    "                                 blank_index=vocab.index(processor.tokenizer.pad_token))\n",
    "\n",
    "\n",
    "greedy_decoder = GreedyDecoder(vocab, blank_index=vocab.index(processor.tokenizer.pad_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2afe432b-65e3-4e87-9fed-24cbb947c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test audio file\n",
    "audio_files_paths = ['./datasets/magister_data_flac_16000/test/11039/2614000/11039-2614000-0000.flac', './datasets/magister_data_flac_16000/test/11039/2614000/11039-2614000-0001.flac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aae0cc8c-08c6-43b9-a284-e79649dc9b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load audio files: \"['./datasets/magister_data_flac_16000/test/11039/2614000/11039-2614000-0000.flac', './datasets/magister_data_flac_16000/test/11039/2614000/11039-2614000-0001.flac']\"\n"
     ]
    }
   ],
   "source": [
    "print(f'Load audio files: \"{audio_files_paths}\"')\n",
    "batch_audio_files, sampling_rate = utils.load_audio_files(audio_files_paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff7a78d1-1c2e-418e-8599-d01c5bf23105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get logits from the Wav2Vec2ForCTC model....\n"
     ]
    }
   ],
   "source": [
    "print('Get logits from the Wav2Vec2ForCTC model....')\n",
    "logits, max_signal_length = utils.get_logits(batch_audio_files, model, processor, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9319ca38-0b62-4ca1-ae78-420afb64a8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.2786, -0.8382, -0.4542,  ..., -1.3852, -4.3337,  9.8525],\n",
       "         [-2.2902, -0.8152, -0.4573,  ..., -1.3913, -4.3236,  9.8550],\n",
       "         [-2.2897, -0.8344, -0.4595,  ..., -1.3903, -4.3181,  9.8491],\n",
       "         ...,\n",
       "         [-2.3060, -0.9024, -0.4289,  ..., -1.4616, -4.3394,  9.8318],\n",
       "         [-2.2989, -0.9266, -0.4229,  ..., -1.4819, -4.3421,  9.8193],\n",
       "         [-2.3130, -0.8996, -0.4738,  ..., -1.4627, -4.3276,  9.8367]],\n",
       "\n",
       "        [[-2.2377, -0.7514, -0.5989,  ..., -1.3682, -4.4281,  9.9067],\n",
       "         [-2.0940, -0.9037, -0.5309,  ..., -1.3416, -4.4453,  9.7667],\n",
       "         [-2.2401, -0.7409, -0.6070,  ..., -1.3521, -4.4228,  9.8985],\n",
       "         ...,\n",
       "         [-2.2740, -0.8447, -0.5058,  ..., -1.3561, -4.4058,  9.8855],\n",
       "         [-2.2687, -0.8514, -0.5020,  ..., -1.3600, -4.4019,  9.8827],\n",
       "         [-2.2638, -0.8597, -0.5046,  ..., -1.3732, -4.3914,  9.8798]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35179ed4-3102-498f-8c2d-963d8fd2d516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 195, 32])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c19cc7a9-55e0-4ceb-81ea-bd8394391ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.3117, -0.8338, -0.4529, -4.2246, -4.4419, -2.5173, -1.2600, -2.6937,\n",
       "        -0.6669, -1.7660, -2.5445, -1.8209, -3.8375, -1.4566, -0.9534, -3.6862,\n",
       "        -2.6184, -2.0723, -1.9897, -2.3756, -0.3536, -2.5347, -1.5390, -1.5076,\n",
       "        -0.9918, -0.3115, -1.2481, -3.2484, -3.4582, -1.3820, -4.3160,  9.8487],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650cda1e-e1f8-46ad-a3ea-f1ee55053295",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Decoding using the Beam Search Decoder....')\n",
    "beam_decoded_output, beam_decoded_offsets = beam_decoder.decode(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93073633-125d-4d2f-bfd4-a6c4004597f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Decoding using the Greedy Decoder....')\n",
    "greedy_decoded_output, greedy_decoded_offsets = greedy_decoder.decode(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531638ed-8924-4cf9-b44e-a4b5bb03b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Printing the output of the first audio file...\\n')\n",
    "\n",
    "print('Greedy Decoding Output:', greedy_decoded_output[1][0])\n",
    "print()\n",
    "print('#'*85)\n",
    "print()\n",
    "print('Beam Search Decoding Output:', beam_decoded_output[1][0]) # print the top prediction of the beam search\n",
    "\n",
    "print('Compute Segments....')\n",
    "batch_segments_list_greedy = utils.get_segments(logits, greedy_decoded_output, max_signal_length, sampling_rate, vocab)\n",
    "batch_segments_list_beam = utils.get_segments(logits, beam_decoded_output, max_signal_length, sampling_rate, vocab)\n",
    "\n",
    "print('Printing the first segment (word) of the first audio file...')\n",
    "print()\n",
    "print('#'*85)\n",
    "print()\n",
    "print('Greedy Decoding Output:', batch_segments_list_greedy[1][0])\n",
    "print()\n",
    "print('Beam Search Decoding Output:', batch_segments_list_beam[1][0])\n",
    "\n",
    "print('Done!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
